{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e663ab4b",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "#### Introduction\n",
    "Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This notebook will walk you through building a complete RAG system using:\n",
    "\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- HuggingFace : For embeddings and language model (you can substitute with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafee87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8726282",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Langchain imports \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document \n",
    "\n",
    "## Vectorstores\n",
    "from langchain_community.vectorstores import Chroma,FAISS\n",
    "\n",
    "##utility imports\n",
    "import numpy as np\n",
    "from typing import List \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85520838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG (Retrieval-Augmented Generation) Architecture:\n",
      "\n",
      "1. Document Loading: Load documents from various sources\n",
      "2. Document Splitting: Break documents into smaller chunks\n",
      "3. Embedding Generation: Convert chunks into vector representations\n",
      "4. Vector Storage: Store embeddings in ChromaDB\n",
      "5. Query Processing: Convert user query to embedding\n",
      "6. Similarity Search: Find relevant chunks from vector store\n",
      "7. Context Augmentation: Combine retrieved chunks with query\n",
      "8. Response Generation: LLM generates answer using context\n",
      "\n",
      "Benefits of RAG:\n",
      "- Reduces hallucinations\n",
      "- Provides up-to-date information\n",
      "- Allows citing sources\n",
      "- Works with domain-specific knowledge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RAG Architecture Overview\n",
    "print(\"\"\"\n",
    "RAG (Retrieval-Augmented Generation) Architecture:\n",
    "\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "\n",
    "Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc00387",
   "metadata": {},
   "source": [
    "### 1. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c98f95b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.\\n    ',\n",
       " '\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "    \n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
    "    and improve from experience without being explicitly programmed. There are three main \n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement \n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised \n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through \n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "    \n",
    "    Deep learning is a subset of machine learning based on artificial neural networks. \n",
    "    These networks are inspired by the human brain and consist of layers of interconnected \n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language \n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers \n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "    \n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language. \n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer \n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "sample_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d6a4b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document create in : C:\\Users\\vigna\\AppData\\Local\\Temp\\tmpwv4s6pfp\n"
     ]
    }
   ],
   "source": [
    "## save sample documents to files\n",
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample document create in : {temp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83caa654",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save sample documents to files\n",
    "import tempfile\n",
    "temp_dir=tempfile.mkdtemp()\n",
    "\n",
    "for i,doc in enumerate(sample_docs):\n",
    "    with open(f\"doc_{i}.txt\",\"w\") as f:\n",
    "        f.write(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a6e3d",
   "metadata": {},
   "source": [
    "### 2.Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "136e5144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loaded 3 document\n",
      "Content preview: \n",
      "    Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that...\n",
      "Metadata: {'source': 'data\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "\n",
    "#load documents form directory\n",
    "loader = DirectoryLoader(\n",
    "    \"data\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls = TextLoader,\n",
    "    loader_kwargs={\"encoding\":\"utf-8\"}\n",
    ")\n",
    "documents = loader.load()\n",
    "print(f\"ðŸ“„ Loaded {len(documents)} document\")\n",
    "print(f\"Content preview: {documents[0].page_content[:100]}...\")\n",
    "print(f\"Metadata: {documents[0].metadata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a1916",
   "metadata": {},
   "source": [
    "### 3) Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e8d643f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 chunks from 3 documents\n",
      "\n",
      " Chunk example : \n",
      "Content: Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn \n",
      "    and improve from experie ...\n",
      "Metadata: {'source': 'data\\\\doc_0.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize text splitter (Recursive  Character Text Splitter)\n",
    "text = documents[0].page_content\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\" \"], # Lets try all these\n",
    "    chunk_size=500, # max chunck size in characters\n",
    "    chunk_overlap=50, # overlap between chuncks\n",
    "    length_function=len # how to measure chunck size\n",
    "    \n",
    ")\n",
    "chunks= text_splitter.split_documents(documents=documents)\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")\n",
    "print(\"\\n Chunk example : \")\n",
    "print(f\"Content: {chunks[0].page_content[:150]} ...\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0420c2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn \\n    and improve from experience without being explicitly programmed. There are three main \\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement \\n    learning. Supervised learning uses labeled data to train models, while unsupervised \\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='data. Reinforcement learning learns through \\n    interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks. \\n    These networks are inspired by the human brain and consist of layers of interconnected \\n    nodes. Deep learning has revolutionized fields like computer vision, natural language \\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly \\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Neural Networks (RNNs) and Transformers \\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language. \\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis, \\n    machine translation, and question answering. Modern NLP heavily relies on transformer \\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand \\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962fc8fc",
   "metadata": {},
   "source": [
    "### 4) Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b24ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Machine learning is fascinating\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "   model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd9118f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88ff831a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embeddings.embed_query(sample_text)\n",
    "len(vector)\n",
    "type(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded84ccb",
   "metadata": {},
   "source": [
    "### Initialize the ChromaDB Vector store and stores the chunks in vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a431e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbea60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c53df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b0d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-kn (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
