{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18810aaf",
   "metadata": {},
   "source": [
    "## LOAD PDF FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e393f401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vigna\\Desktop\\RAG-KN\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader,PyMuPDFLoader,UnstructuredPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa0641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyPDFLoader\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswaniâˆ—\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeerâˆ—\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmarâˆ—\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreitâˆ—\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jonesâˆ—\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomezâˆ— â€ \n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "Åukasz Kaiser âˆ—\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhinâˆ— â€¡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
      "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
      "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "âˆ—Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\n",
      "has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\n",
      "attention and the parameter-free position representation and became the other person involved in nearly every\n",
      "detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\n",
      "tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\n",
      "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
      "implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\n",
      "our research.\n",
      "â€ Work performed while at Google Brain.\n",
      "â€¡Work performed while at Google Research.\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n",
      "arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n"
     ]
    }
   ],
   "source": [
    "### PyPDFLoader\n",
    "print(\"PyPDFLoader\")\n",
    "try:\n",
    "    pypdf_loader = PyPDFLoader(\"data/pdf/attention.pdf\")\n",
    "    pypdf_docs = pypdf_loader.load()\n",
    "    print(pypdf_docs[0].page_content)\n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c229f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMuPDFLoader\n",
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswaniâˆ—\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeerâˆ—\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmarâˆ—\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreitâˆ—\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jonesâˆ—\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomezâˆ— â€ \n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "Åukasz Kaiser âˆ—\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhinâˆ— â€¡\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
      "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
      "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "âˆ—Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\n",
      "has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\n",
      "attention and the parameter-free position representation and became the other person involved in nearly every\n",
      "detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\n",
      "tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\n",
      "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
      "implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\n",
      "our research.\n",
      "â€ Work performed while at Google Brain.\n",
      "â€¡Work performed while at Google Research.\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n",
      "arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n"
     ]
    }
   ],
   "source": [
    "### PyMuPDFLoader\n",
    "print(\"PyMuPDFLoader\")\n",
    "try:\n",
    "    pymupdf_loader = PyMuPDFLoader(\"data/pdf/attention.pdf\")\n",
    "    pymupdf_docs = pypdf_loader.load()\n",
    "    print(pymupdf_docs[0].page_content)\n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ced6eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š PDF Loader Comparison:\n",
      "\n",
      "PyPDFLoader:\n",
      "  âœ… Simple and reliable\n",
      "  âœ… Good for most PDFs\n",
      "  âœ… Preserves page numbers\n",
      "  âŒ Basic text extraction\n",
      "  Use when: Standard text PDFs\n",
      "\n",
      "PyMuPDFLoader:\n",
      "  âœ… Fast processing\n",
      "  âœ… Good text extraction\n",
      "  âœ… Image extraction support\n",
      "  Use when: Speed is important\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š PDF Loader Comparison\n",
    "print(\"\\nðŸ“Š PDF Loader Comparison:\")\n",
    "print(\"\\nPyPDFLoader:\")\n",
    "print(\"  âœ… Simple and reliable\")\n",
    "print(\"  âœ… Good for most PDFs\")\n",
    "print(\"  âœ… Preserves page numbers\")\n",
    "print(\"  âŒ Basic text extraction\")\n",
    "print(\"  Use when: Standard text PDFs\")\n",
    "\n",
    "print(\"\\nPyMuPDFLoader:\")\n",
    "print(\"  âœ… Fast processing\")\n",
    "print(\"  âœ… Good text extraction\")\n",
    "print(\"  âœ… Image extraction support\")\n",
    "print(\"  Use when: Speed is important\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e0d2a",
   "metadata": {},
   "source": [
    "### Handling PDF Challenges \n",
    "ðŸŽ¯ Purpose of This Section\n",
    "PDFs are notoriously difficult to parse because they:\n",
    "\n",
    "- Store text in complex ways (not just simple text)\n",
    "- Can have formatting issues\n",
    "- May contain scanned images (requiring OCR)\n",
    "- Often have extraction artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6bacb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:\n",
      "Company Financial Report\n",
      "\n",
      "\n",
      "    The ï¬nancial performance for ï¬scal year 2024\n",
      "    shows signiï¬cant growth in proï¬tability.\n",
      "\n",
      "\n",
      "\n",
      "    Revenue increased by 25%.\n",
      "\n",
      "The company's efï¬ciency improved due to workï¬‚ow\n",
      "optimization.\n",
      "\n",
      "\n",
      "Page 1 of 10\n",
      "\n",
      "\n",
      "AFTER:\n",
      "\"Company Financial Report The financial performance for fiscal year 2024 shows significant growth in profitability. Revenue increased by 25%. The company's efficiency improved due to workflow optimization. Page 1 of 10\"\n"
     ]
    }
   ],
   "source": [
    "# Example of raw PDF extraction\n",
    "raw_pdf_text = \"\"\"Company Financial Report\n",
    "\n",
    "\n",
    "    The ï¬nancial performance for ï¬scal year 2024\n",
    "    shows signiï¬cant growth in proï¬tability.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Revenue increased by 25%.\n",
    "    \n",
    "The company's efï¬ciency improved due to workï¬‚ow\n",
    "optimization.\n",
    "\n",
    "\n",
    "Page 1 of 10\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Apply the cleaning function\n",
    "def clean_text(text):\n",
    "    # Remove excessive whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Fix ligatures\n",
    "    text = text.replace(\"ï¬\", \"fi\")\n",
    "    text = text.replace(\"ï¬‚\", \"fl\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "cleaned = clean_text(raw_pdf_text)\n",
    "print(\"BEFORE:\")\n",
    "print(repr(raw_pdf_text))\n",
    "print(\"\\nAFTER:\")\n",
    "print((cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e895e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbae6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "class SmartPDFProcessor:\n",
    "    \"\"\" Advanced PDF Processing with error handling \"\"\"\n",
    "    def __init__(self,chunk_size=1000,chunk_overlap=100):\n",
    "        self.chunk_size=chunk_size\n",
    "        self.chunk_overlap=chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=self.chunk_size,\n",
    "            chunk_overlap=self.chunk_overlap,\n",
    "            separators=[\" \"]\n",
    "        )\n",
    "    def clean_text(self,text):\n",
    "            # Remove excessive whitespace\n",
    "            text = \" \".join(text.split())\n",
    "            \n",
    "            # Fix ligatures\n",
    "            text = text.replace(\"ï¬\", \"fi\")\n",
    "            text = text.replace(\"ï¬‚\", \"fl\")\n",
    "            \n",
    "            return text\n",
    "    def process_pdf(self,pdf_path:str)->List[Document]:\n",
    "        \"\"\"Process PDF with smart chunking and metadata enhancement \"\"\"\n",
    "        # Load PDF\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages= loader.load()\n",
    "\n",
    "        ## Process each page\n",
    "        processed_chunks = []\n",
    "        for page_num,page in enumerate(pages):\n",
    "            ## Clean text \n",
    "            cleaned_text = self.clean_text(page.page_content)\n",
    "\n",
    "            ## Skip nearly empty pages\n",
    "            if len(cleaned_text.strip())<50:\n",
    "                 continue \n",
    "                 \n",
    "            ## Create chunks with enhanced metadata\n",
    "\n",
    "            chunks = self.text_splitter.create_documents(\n",
    "                texts=[cleaned_text],\n",
    "                metadatas=[{\n",
    "                     **page.metadata,\n",
    "                     \"page\":page_num+1,\n",
    "                     \"total_pages\":len(pages),\n",
    "                     \"chunk_method\":\"smart_pdf_processor\",\n",
    "                     \"char_count\":len(cleaned_text)\n",
    "\n",
    "                }]\n",
    "            )\n",
    "            # print(chunks)\n",
    "            processed_chunks.extend(chunks)\n",
    "        return processed_chunks\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51fb5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SmartPDFProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b5b7db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed into 49 smart chunks\n",
      "\n",
      " Sample chunk metadata: \n",
      "producer:pdfTeX-1.40.25\n",
      "creator:LaTeX with hyperref\n",
      "creationdate:2024-04-10T21:11:43+00:00\n",
      "author:\n",
      "keywords:\n",
      "moddate:2024-04-10T21:11:43+00:00\n",
      "ptex.fullbanner:This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n",
      "subject:\n",
      "title:\n",
      "trapped:/False\n",
      "source:data/pdf/attention.pdf\n",
      "total_pages:15\n",
      "page:1\n",
      "page_label:1\n",
      "chunk_method:smart_pdf_processor\n",
      "char_count:2858\n"
     ]
    }
   ],
   "source": [
    "## Process a PDF If available\n",
    "try:\n",
    "    smart_chunks = processor.process_pdf(\"data/pdf/attention.pdf\")\n",
    "    print(f\"processed into {len(smart_chunks)} smart chunks\")\n",
    "\n",
    "    # show enhanced chunks\n",
    "    if smart_chunks:\n",
    "        print(\"\\n Sample chunk metadata: \")\n",
    "        for key,value in smart_chunks[0].metadata.items():\n",
    "            print(f\"{key}:{value}\")\n",
    "except Exception as e:\n",
    "    print(f\"Processing Error : {e} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3116363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d19fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-kn (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
